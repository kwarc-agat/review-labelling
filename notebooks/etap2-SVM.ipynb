{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwarc\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in my opinion , a movie reviewer's most import...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you can watch this movie , that is based on a ...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is asking a lot to believe , and though i...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no heroes and no story are the main attributes...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is not an art movie , yet i saw it an art...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>the conventional wisdom is that movie sequels ...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>nicolas roeg's mesmerizing 1971 film walkabout...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>the movie air force one should require a docto...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>\" well , jones , at least you haven't forgotte...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>in a time of bloated productions where special...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5006 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating  label3  \\\n",
       "0     in my opinion , a movie reviewer's most import...     0.1       0   \n",
       "1     you can watch this movie , that is based on a ...     0.2       0   \n",
       "2     this is asking a lot to believe , and though i...     0.2       0   \n",
       "3     no heroes and no story are the main attributes...     0.2       0   \n",
       "4     this is not an art movie , yet i saw it an art...     0.2       0   \n",
       "...                                                 ...     ...     ...   \n",
       "5001  the conventional wisdom is that movie sequels ...     0.9       2   \n",
       "5002  nicolas roeg's mesmerizing 1971 film walkabout...     0.9       2   \n",
       "5003  the movie air force one should require a docto...     0.9       2   \n",
       "5004  \" well , jones , at least you haven't forgotte...     0.9       2   \n",
       "5005  in a time of bloated productions where special...     0.9       2   \n",
       "\n",
       "      label4  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "5001       3  \n",
       "5002       3  \n",
       "5003       3  \n",
       "5004       3  \n",
       "5005       3  \n",
       "\n",
       "[5006 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5006x41631 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 759861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    "X_counts = vectorizer.fit_transform(df['review'].values)\n",
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5006x41631 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 759861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_counts)\n",
    "X_tf = tf_transformer.transform(X_counts)\n",
    "X_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label3 = df['label3'].values\n",
    "Y_label4 = df['label4'].values\n",
    "Y_label3_names = np.unique(Y_label3).tolist()\n",
    "Y_label4_names = np.unique(Y_label4).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts_train, X_counts_test, Y_label3_counts_train, Y_label3_counts_test = train_test_split(X_counts, Y_label3, test_size=0.1)\n",
    "X_tf_train, X_tf_test, Y_label3_tf_train, Y_label3_tf_test = train_test_split(X_tf, Y_label3, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "clf_svm_counts = SVC(kernel='linear').fit(X_counts_train, Y_label3_counts_train)\n",
    "clf_svm_tf = SVC(kernel='linear').fit(X_tf_train, Y_label3_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_counts = clf_svm_counts.predict(X_counts_test)\n",
    "pred_svm_tf = clf_svm_tf.predict(X_tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_counts - Y_label3: 0.6087824351297405\n",
      "X_tf - Y_label3: 0.688622754491018\n"
     ]
    }
   ],
   "source": [
    "print(\"X_counts - Y_label3: \"+ str(np.mean(pred_svm_counts == Y_label3_counts_test)))\n",
    "print(\"X_tf - Y_label3: \"+ str(np.mean(pred_svm_tf == Y_label3_tf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58       121\n",
      "           1       0.54      0.53      0.53       196\n",
      "           2       0.71      0.70      0.71       184\n",
      "\n",
      "    accuracy                           0.61       501\n",
      "   macro avg       0.61      0.61      0.61       501\n",
      "weighted avg       0.61      0.61      0.61       501\n",
      "\n",
      "[[ 73  42   6]\n",
      " [ 47 103  46]\n",
      " [  9  46 129]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_label3_counts_test, pred_svm_counts, labels=Y_label3_names))\n",
    "print(metrics.confusion_matrix(Y_label3_counts_test, pred_svm_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.56       126\n",
      "           1       0.58      0.72      0.64       186\n",
      "           2       0.84      0.79      0.82       189\n",
      "\n",
      "    accuracy                           0.69       501\n",
      "   macro avg       0.70      0.67      0.67       501\n",
      "weighted avg       0.70      0.69      0.69       501\n",
      "\n",
      "[[ 61  62   3]\n",
      " [ 26 134  26]\n",
      " [  3  36 150]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_label3_tf_test, pred_svm_tf, labels=Y_label3_names))\n",
    "print(metrics.confusion_matrix(Y_label3_tf_test, pred_svm_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - with GridSearch - linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_linear = [{'kernel': ['linear'], 'C': [0.1, 1, 10, 100, 1000]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_linear, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, kernel=linear, accuracy=0.616, f1=0.609, precision=0.618, recall=0.604, total=  34.0s\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   33.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, kernel=linear, accuracy=0.631, f1=0.624, precision=0.630, recall=0.621, total=  33.2s\n",
      "[CV] C=1, kernel=linear ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, kernel=linear, accuracy=0.611, f1=0.605, precision=0.610, recall=0.601, total=  33.7s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV]  C=1, kernel=linear, accuracy=0.633, f1=0.627, precision=0.631, recall=0.624, total=  33.9s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV]  C=10, kernel=linear, accuracy=0.611, f1=0.605, precision=0.610, recall=0.601, total=  32.7s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV]  C=10, kernel=linear, accuracy=0.633, f1=0.627, precision=0.631, recall=0.624, total=  33.1s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV]  C=100, kernel=linear, accuracy=0.611, f1=0.605, precision=0.610, recall=0.601, total=  33.7s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV]  C=100, kernel=linear, accuracy=0.633, f1=0.627, precision=0.631, recall=0.624, total=  35.9s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV]  C=1000, kernel=linear, accuracy=0.611, f1=0.605, precision=0.610, recall=0.601, total=  35.5s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV]  C=1000, kernel=linear, accuracy=0.633, f1=0.627, precision=0.631, recall=0.624, total=  36.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_counts_train, Y_label3_counts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "0.616851425944893\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59       121\n",
      "           1       0.54      0.52      0.53       196\n",
      "           2       0.72      0.72      0.72       184\n",
      "\n",
      "    accuracy                           0.61       501\n",
      "   macro avg       0.61      0.61      0.61       501\n",
      "weighted avg       0.61      0.61      0.61       501\n",
      "\n",
      "[[ 73  42   6]\n",
      " [ 48 102  46]\n",
      " [  7  45 132]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_counts_test)\n",
    "print(metrics.classification_report(Y_label3_counts_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_counts_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - with GridSearch - rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_rbf = [{'kernel': ['rbf'], 'gamma': [10, 1, 1e-1, 1e-2, 1e-3]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_rbf, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] gamma=10, kernel=rbf ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=10, kernel=rbf, accuracy=0.386, f1=0.194, precision=0.794, recall=0.338, total=  40.6s\n",
      "[CV] gamma=10, kernel=rbf ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   40.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=10, kernel=rbf, accuracy=0.386, f1=0.195, precision=0.794, recall=0.339, total=  39.4s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=1, kernel=rbf, accuracy=0.386, f1=0.194, precision=0.794, recall=0.338, total=  38.5s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV]  gamma=1, kernel=rbf, accuracy=0.386, f1=0.195, precision=0.794, recall=0.339, total=  37.3s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV]  gamma=0.1, kernel=rbf, accuracy=0.387, f1=0.198, precision=0.747, recall=0.340, total=  35.9s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV]  gamma=0.1, kernel=rbf, accuracy=0.398, f1=0.227, precision=0.646, recall=0.350, total=  35.6s\n",
      "[CV] gamma=0.01, kernel=rbf ..........................................\n",
      "[CV]  gamma=0.01, kernel=rbf, accuracy=0.496, f1=0.393, precision=0.620, recall=0.440, total=  40.0s\n",
      "[CV] gamma=0.01, kernel=rbf ..........................................\n",
      "[CV]  gamma=0.01, kernel=rbf, accuracy=0.480, f1=0.385, precision=0.606, recall=0.428, total=  39.3s\n",
      "[CV] gamma=0.001, kernel=rbf .........................................\n",
      "[CV]  gamma=0.001, kernel=rbf, accuracy=0.552, f1=0.449, precision=0.702, recall=0.490, total=  35.3s\n",
      "[CV] gamma=0.001, kernel=rbf .........................................\n",
      "[CV]  gamma=0.001, kernel=rbf, accuracy=0.552, f1=0.462, precision=0.670, recall=0.493, total=  35.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'gamma': [10, 1, 0.1, 0.01, 0.001],\n",
       "                          'kernel': ['rbf']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_counts_train, Y_label3_counts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.26      0.40       121\n",
      "           1       0.52      0.78      0.62       196\n",
      "           2       0.76      0.67      0.71       184\n",
      "\n",
      "    accuracy                           0.62       501\n",
      "   macro avg       0.68      0.57      0.58       501\n",
      "weighted avg       0.67      0.62      0.60       501\n",
      "\n",
      "[[ 32  84   5]\n",
      " [  8 153  35]\n",
      " [  1  59 124]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "pred = clf.predict(X_counts_test)\n",
    "print(metrics.classification_report(Y_label3_counts_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_counts_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_rbf = [{'kernel': ['poly'], 'degree': [1, 2, 3, 4, 5]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_rbf, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] degree=1, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=1, kernel=poly, accuracy=0.604, f1=0.574, precision=0.642, recall=0.568, total=  35.9s\n",
      "[CV] degree=1, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=1, kernel=poly, accuracy=0.621, f1=0.593, precision=0.666, recall=0.585, total=  34.9s\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=2, kernel=poly, accuracy=0.530, f1=0.453, precision=0.640, recall=0.479, total=  23.9s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV]  degree=2, kernel=poly, accuracy=0.512, f1=0.446, precision=0.600, recall=0.466, total=  20.9s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV]  degree=3, kernel=poly, accuracy=0.440, f1=0.313, precision=0.563, recall=0.391, total=  21.0s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV]  degree=3, kernel=poly, accuracy=0.429, f1=0.316, precision=0.538, recall=0.384, total=  21.6s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV]  degree=4, kernel=poly, accuracy=0.402, f1=0.237, precision=0.566, recall=0.355, total=  20.6s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV]  degree=4, kernel=poly, accuracy=0.397, f1=0.246, precision=0.536, recall=0.353, total=  20.7s\n",
      "[CV] degree=5, kernel=poly ...........................................\n",
      "[CV]  degree=5, kernel=poly, accuracy=0.387, f1=0.207, precision=0.536, recall=0.341, total=  20.8s\n",
      "[CV] degree=5, kernel=poly ...........................................\n",
      "[CV]  degree=5, kernel=poly, accuracy=0.384, f1=0.208, precision=0.513, recall=0.339, total=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'degree': [1, 2, 3, 4, 5], 'kernel': ['poly']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_counts_train, Y_label3_counts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'degree': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.44      0.54       121\n",
      "           1       0.55      0.71      0.62       196\n",
      "           2       0.76      0.70      0.73       184\n",
      "\n",
      "    accuracy                           0.64       501\n",
      "   macro avg       0.67      0.62      0.63       501\n",
      "weighted avg       0.66      0.64      0.64       501\n",
      "\n",
      "[[ 53  64   4]\n",
      " [ 20 140  36]\n",
      " [  4  52 128]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "pred = clf.predict(X_counts_test)\n",
    "print(metrics.classification_report(Y_label3_counts_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_counts_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - with GridSearch - linear TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_linear = [{'kernel': ['linear'], 'C': [0.1, 1, 10, 100, 1000]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_linear, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\kwarc\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, kernel=linear, accuracy=0.467, f1=0.324, precision=0.429, recall=0.407, total=  19.1s\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV]  C=0.1, kernel=linear, accuracy=0.468, f1=0.326, precision=0.424, recall=0.408, total=  19.9s\n",
      "[CV] C=1, kernel=linear ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   38.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, kernel=linear, accuracy=0.650, f1=0.635, precision=0.668, recall=0.625, total=  17.0s\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV]  C=1, kernel=linear, accuracy=0.634, f1=0.620, precision=0.656, recall=0.609, total=  17.5s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV]  C=10, kernel=linear, accuracy=0.636, f1=0.633, precision=0.634, recall=0.632, total=  19.0s\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV]  C=10, kernel=linear, accuracy=0.624, f1=0.616, precision=0.623, recall=0.612, total=  20.0s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV]  C=100, kernel=linear, accuracy=0.636, f1=0.632, precision=0.633, recall=0.631, total=  18.9s\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV]  C=100, kernel=linear, accuracy=0.624, f1=0.616, precision=0.623, recall=0.612, total=  19.0s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV]  C=1000, kernel=linear, accuracy=0.636, f1=0.632, precision=0.633, recall=0.631, total=  19.2s\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV]  C=1000, kernel=linear, accuracy=0.624, f1=0.616, precision=0.623, recall=0.612, total=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_tf_train, Y_label3_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "0.6275176177163068\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.56       126\n",
      "           1       0.58      0.72      0.64       186\n",
      "           2       0.84      0.79      0.82       189\n",
      "\n",
      "    accuracy                           0.69       501\n",
      "   macro avg       0.70      0.67      0.67       501\n",
      "weighted avg       0.70      0.69      0.69       501\n",
      "\n",
      "[[ 61  62   3]\n",
      " [ 26 134  26]\n",
      " [  3  36 150]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_tf_test)\n",
    "print(metrics.classification_report(Y_label3_tf_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_tf_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - with GridSearch - rbf TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_rbf = [{'kernel': ['rbf'], 'gamma': [10, 1, 1e-1, 1e-2, 1e-3]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_rbf, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] gamma=10, kernel=rbf ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=10, kernel=rbf, accuracy=0.391, f1=0.203, precision=0.744, recall=0.341, total=  20.1s\n",
      "[CV] gamma=10, kernel=rbf ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=10, kernel=rbf, accuracy=0.391, f1=0.201, precision=0.795, recall=0.341, total=  20.0s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=1, kernel=rbf, accuracy=0.611, f1=0.567, precision=0.680, recall=0.566, total=  20.0s\n",
      "[CV] gamma=1, kernel=rbf .............................................\n",
      "[CV]  gamma=1, kernel=rbf, accuracy=0.623, f1=0.589, precision=0.674, recall=0.583, total=  20.4s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwarc\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gamma=0.1, kernel=rbf, accuracy=0.525, f1=0.402, precision=0.379, recall=0.459, total=  18.8s\n",
      "[CV] gamma=0.1, kernel=rbf ...........................................\n",
      "[CV]  gamma=0.1, kernel=rbf, accuracy=0.543, f1=0.414, precision=0.380, recall=0.474, total=  19.9s\n",
      "[CV] gamma=0.01, kernel=rbf ..........................................\n",
      "[CV]  gamma=0.01, kernel=rbf, accuracy=0.384, f1=0.185, precision=0.128, recall=0.333, total=  18.8s\n",
      "[CV] gamma=0.01, kernel=rbf ..........................................\n",
      "[CV]  gamma=0.01, kernel=rbf, accuracy=0.384, f1=0.185, precision=0.128, recall=0.333, total=  18.9s\n",
      "[CV] gamma=0.001, kernel=rbf .........................................\n",
      "[CV]  gamma=0.001, kernel=rbf, accuracy=0.384, f1=0.185, precision=0.128, recall=0.333, total=  19.6s\n",
      "[CV] gamma=0.001, kernel=rbf .........................................\n",
      "[CV]  gamma=0.001, kernel=rbf, accuracy=0.384, f1=0.185, precision=0.128, recall=0.333, total=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'gamma': [10, 1, 0.1, 0.01, 0.001],\n",
       "                          'kernel': ['rbf']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_tf_train, Y_label3_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.43       126\n",
      "           1       0.54      0.81      0.65       186\n",
      "           2       0.83      0.76      0.79       189\n",
      "\n",
      "    accuracy                           0.66       501\n",
      "   macro avg       0.71      0.62      0.62       501\n",
      "weighted avg       0.70      0.66      0.65       501\n",
      "\n",
      "[[ 38  83   5]\n",
      " [ 11 150  25]\n",
      " [  2  43 144]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "pred = clf.predict(X_tf_test)\n",
    "print(metrics.classification_report(Y_label3_tf_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_tf_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - poly TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_rbf = [{'kernel': ['poly'], 'degree': [1, 2, 3, 4, 5]}]\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "clf = GridSearchCV(SVC(), tuned_parameters_rbf, scoring=scoring,\n",
    "                  cv=2, verbose=3, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] degree=1, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=1, kernel=poly, accuracy=0.650, f1=0.635, precision=0.668, recall=0.625, total=  19.9s\n",
      "[CV] degree=1, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=1, kernel=poly, accuracy=0.633, f1=0.619, precision=0.655, recall=0.609, total=  18.6s\n",
      "[CV] degree=2, kernel=poly ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   38.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  degree=2, kernel=poly, accuracy=0.613, f1=0.573, precision=0.669, recall=0.570, total=  20.2s\n",
      "[CV] degree=2, kernel=poly ...........................................\n",
      "[CV]  degree=2, kernel=poly, accuracy=0.623, f1=0.589, precision=0.665, recall=0.583, total=  21.4s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV]  degree=3, kernel=poly, accuracy=0.542, f1=0.454, precision=0.625, recall=0.485, total=  21.7s\n",
      "[CV] degree=3, kernel=poly ...........................................\n",
      "[CV]  degree=3, kernel=poly, accuracy=0.577, f1=0.495, precision=0.617, recall=0.519, total=  21.2s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV]  degree=4, kernel=poly, accuracy=0.487, f1=0.376, precision=0.627, recall=0.430, total=  20.3s\n",
      "[CV] degree=4, kernel=poly ...........................................\n",
      "[CV]  degree=4, kernel=poly, accuracy=0.548, f1=0.447, precision=0.604, recall=0.486, total=  20.1s\n",
      "[CV] degree=5, kernel=poly ...........................................\n",
      "[CV]  degree=5, kernel=poly, accuracy=0.463, f1=0.351, precision=0.637, recall=0.407, total=  19.8s\n",
      "[CV] degree=5, kernel=poly ...........................................\n",
      "[CV]  degree=5, kernel=poly, accuracy=0.534, f1=0.418, precision=0.660, recall=0.469, total=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(),\n",
       "             param_grid=[{'degree': [1, 2, 3, 4, 5], 'kernel': ['poly']}],\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score, average=macro),\n",
       "                      'precision': make_scorer(precision_score, average=macro),\n",
       "                      'recall': make_scorer(recall_score, average=macro)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_tf_train, Y_label3_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'degree': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.56       126\n",
      "           1       0.58      0.72      0.64       186\n",
      "           2       0.84      0.79      0.82       189\n",
      "\n",
      "    accuracy                           0.69       501\n",
      "   macro avg       0.70      0.67      0.67       501\n",
      "weighted avg       0.70      0.69      0.69       501\n",
      "\n",
      "[[ 61  62   3]\n",
      " [ 26 134  26]\n",
      " [  3  36 150]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed classification report:\")\n",
    "pred = clf.predict(X_tf_test)\n",
    "print(metrics.classification_report(Y_label3_tf_test, pred))\n",
    "print(metrics.confusion_matrix(Y_label3_tf_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
